{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KSNVlQK1sIpMD5NJz_gLzwuE1-TM4qFt",
      "authorship_tag": "ABX9TyMhNtjRKBIh3t+wjTfuo1Np",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NileshCT/Machine_Learning_Models/blob/main/Node_creat_for_kedro_pipeline_On_WeatherAUS_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LTD_FxD2YfI5"
      },
      "outputs": [],
      "source": [
        "#Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "  \"\"\"importing dataset\n",
        "  output=importing dataset and converting into dataframe.\"\"\"\n",
        "  df=pd.read_csv(\"/content/drive/MyDrive/weatherAUS.csv.zip\")\n",
        "  return df"
      ],
      "metadata": {
        "id": "A2ldCuPCYrm-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=get_data()"
      ],
      "metadata": {
        "id": "tM4j7vuEkzFK"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_treatment(df):\n",
        "  \"\"\"Drop date column from dataframe.\n",
        "  Arg=df\n",
        "  output=Dataframe with no date column.\"\"\"\n",
        "  df.drop([\"Date\"],axis=1,inplace=True)\n",
        "  return df\n",
        "data=data_treatment(df)"
      ],
      "metadata": {
        "id": "aaubujzRfhGU"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_nan(df):\n",
        "  \"\"\"Selecting nan records from target variable.\n",
        "\n",
        "  Arg=df\n",
        "\n",
        "  output=Records with all nan values from target variable.\"\"\"\n",
        "  a=[(i,index) for i,index in enumerate(df[\"RainTomorrow\"]) if pd.isna(index)]\n",
        "  t= pd.DataFrame(a).set_index(0)\n",
        "  return t"
      ],
      "metadata": {
        "id": "xpGCbgdsuryR"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=target_nan(df)\n"
      ],
      "metadata": {
        "id": "AggBUC7qvvdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference data extraction.\n",
        "def inference(t):\n",
        "  \"\"\"Separating inference data\n",
        "\n",
        "  Arg=t\n",
        "  \n",
        "  output=dataframe of inference data.\"\"\"\n",
        "  index_nan=t.index.tolist()\n",
        "  df_inference=df.iloc[index_nan]\n",
        "  return df_inference\n",
        "df_inference=inference(t)"
      ],
      "metadata": {
        "id": "EIuImBT3v8EP"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get training data for modelling.\n",
        "def training_data(df_inference):\n",
        "  \"\"\"Separating training data from original dataframe\n",
        "\n",
        "  Arg=df_inference\n",
        "\n",
        "  output=New dataframe with training data only.\"\"\"\n",
        "  index_nan=t.index.tolist()\n",
        "  b=[]\n",
        "  for i in range(df.shape[0]):\n",
        "    if i not in index_nan:\n",
        "      b.append(i)\n",
        "  return b\n"
      ],
      "metadata": {
        "id": "BobewtWn027d"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=training_data(df_inference)"
      ],
      "metadata": {
        "id": "nCmK9jFf8n-5"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_data(b):\n",
        "  \"\"\"Displaying training data\n",
        "\n",
        "  Arg=b\n",
        "\n",
        "  Output=Seaparate training_data from original dataframe.\"\"\"\n",
        "  df_training_data=df.iloc[b]\n",
        "  return df_training_data"
      ],
      "metadata": {
        "id": "PJ65B3Kt8wi4"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_training_data=get_training_data(b)\n",
        "df_training_data"
      ],
      "metadata": {
        "id": "h5yms_JA2qG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treat_missing(df_training_data):\n",
        "  \"\"\"treat missing values with ffill and bfill method\n",
        "\n",
        "  Arg=df_training_data\n",
        "\n",
        "  output=nan values from training data get fill with the ffill and bfill method.\"\"\"\n",
        "  df_treat_training_data=df_training_data.fillna(method=\"ffill\",axis=0).fillna(method=\"bfill\",axis=0)\n",
        "  return df_treat_training_data\n",
        "df_treat_training_data=treat_missing(df_training_data)"
      ],
      "metadata": {
        "id": "gHfbTTWI5UKy"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_data_split(df_treat_training_data):\n",
        "  \"\"\"Training data spliting ie.separating predictors and response variables.\n",
        "\n",
        "  Arg=df_treat_training_data\n",
        "\n",
        "  Output=Target variable get separated from main traing data.\"\"\"\n",
        "  X_training=df_treat_training_data.drop([\"RainTomorrow\"],axis=1)\n",
        "  y_training=df_treat_training_data[\"RainTomorrow\"]\n",
        "  return X_training, y_training\n",
        "X_training, y_training=training_data_split(df_treat_training_data)"
      ],
      "metadata": {
        "id": "PohDJrbVExbd"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "L_Encoder=preprocessing.LabelEncoder()\n",
        "def lebal_encoder(X_training):\n",
        "  \"\"\"Lebal encoding on the discrite varibales.\n",
        "\n",
        "  Arg=X_training\n",
        "\n",
        "  Output=converting categorical data into numeric variable.\"\"\"\n",
        "  X_training[\"Location\"]=L_Encoder.fit_transform(X_training[\"Location\"])\n",
        "  X_training[\"WindGustDir\"]=L_Encoder.fit_transform(X_training[\"WindGustDir\"])\n",
        "  X_training[\"WindDir9am\"]=L_Encoder.fit_transform(X_training[\"WindDir9am\"])\n",
        "  X_training[\"WindDir3pm\"]=L_Encoder.fit_transform(X_training[\"WindDir3pm\"])\n",
        "  X_training[\"RainToday\"]=L_Encoder.fit_transform(X_training[\"RainToday\"])\n",
        "  return X_training\n",
        "X_training=lebal_encoder(X_training)\n"
      ],
      "metadata": {
        "id": "RKCdDSuTC5CH"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scalar=StandardScaler()\n",
        "def df_transform(X_training):\n",
        "  \"\"\"perform process of standardization on X_reaining data to minimizes the skewness from records\n",
        "\n",
        "  Arg=X_training\n",
        "\n",
        "  Output=Gets records with some what normal distribution in the records.\"\"\"\n",
        "  model=scalar.fit(X_training)\n",
        "  X_training1=model.transform(X_training)\n",
        "  return X_training1\n",
        "X_training1=df_transform(X_training)"
      ],
      "metadata": {
        "id": "sPgZ3BRTHShV"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def modelling(X_training1):\n",
        "  \"\"\"Splitting of the x_traing data into X_train,X_test,y_train,y_test data for predicting the output.\n",
        "\n",
        "  Arg=X_training1\n",
        "\n",
        "  output=Get splitted data in the form of train and test data.\"\"\"\n",
        "  X_train,X_test,y_train,y_test=train_test_split(X_training1,y_training,random_state=0,test_size=0.20)\n",
        "  return X_train,X_test,y_train,y_test\n",
        "X_train,X_test,y_train,y_test=modelling(X_training1)"
      ],
      "metadata": {
        "id": "lzvLsDZPOmSF"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
        "def logReg(X_train,X_test,y_train,y_test):\n",
        "  \"\"\"applying the logistic regression algo on the data after split.\n",
        "\n",
        "  Arg=X_train,X_test,y_train,y_test\n",
        "\n",
        "  Output=data training and output prediction.\"\"\"\n",
        "  logreg.fit(X_train, y_train)\n",
        "  y_pred_train = logreg.predict(X_train)\n",
        "  y_pred_test = logreg.predict(X_test)\n",
        "  return y_pred_train, y_pred_test\n",
        "y_pred_train,y_pred_test=logReg(X_train,X_test,y_train,y_test)  "
      ],
      "metadata": {
        "id": "2sOde-gFQ0Sd"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def r2_score(y_pred_train,y_pred_test):\n",
        "  \"\"\"calculate r2_score\n",
        "\n",
        "  Arg=y_pred_train,y_pred_test\n",
        "\n",
        "  output=get r2 score to evaluate the model performance on train and test data.\"\"\"\n",
        "  r2_score_train=accuracy_score(y_train, y_pred_train)\n",
        "  r2_score_test=accuracy_score(y_test, y_pred_test)\n",
        "  return r2_score_train,r2_score_test\n",
        "r2_score_train=r2_score(y_pred_train,y_pred_test)\n",
        "r2_score_test=r2_score(y_pred_train,y_pred_test)"
      ],
      "metadata": {
        "id": "G1H0BBCYS3VB"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score_train\n",
        "r2_score_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJs48RXqVQzU",
        "outputId": "f9ff8768-924b-44c5-ed21-d2a21fd40b95"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8413154702252228, 0.8427511515876086)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    }
  ]
}